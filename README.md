# TIMELY-Bench

**A Benchmark for Time-Aligned Fusion of Clinical Time-Series and Notes in MIMIC**

[![License](https://img.shields.io/badge/License-PhysioNet-blue.svg)](https://physionet.org/)
[![Python](https://img.shields.io/badge/Python-3.12+-green.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)

---

## ğŸ¯ Overview

TIMELY-Bench is a reproducible benchmark for multimodal EHR fusion that:

1. **Curates** benchmark-ready cohorts from MIMIC-IV with transparent alignment protocols
2. **Implements** lightweight baselines and unified metrics for fair comparison
3. **Releases** data schemas, code, and documentation for the community

---

## ğŸ“Š Key Results

| Model | Mortality AUROC | Description |
|-------|-----------------|-------------|
| **Enhanced GRU** | **0.831** | Time-series + LLM + Annotations |
| Temporal GRU | 0.824 | Time-series + LLM |
| XGBoost (Tabular) | 0.804 | Tabular features + Annotations |
| Early Fusion | 0.779 | Feature concatenation |
| Text-only | 0.759 | Annotation features only |

---

## ğŸ“ Project Structure

```
TIMELY-Bench_Final/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ baselines/              # Model training scripts
â”‚   â”‚   â”œâ”€â”€ train_tabular_baselines.py
â”‚   â”‚   â”œâ”€â”€ train_text_only.py
â”‚   â”‚   â”œâ”€â”€ train_enhanced_gru.py
â”‚   â”‚   â”œâ”€â”€ train_fusion.py
â”‚   â”‚   â”œâ”€â”€ train_aligner_comparison.py
â”‚   â”‚   â”œâ”€â”€ eval_calibration.py
â”‚   â”‚   â””â”€â”€ eval_note_ablation.py
â”‚   â”œâ”€â”€ data_processing/        # Data processing pipeline
â”‚   â”‚   â”œâ”€â”€ episode_builder.py
â”‚   â”‚   â”œâ”€â”€ pattern_detector.py
â”‚   â”‚   â””â”€â”€ smart_rule_matcher_full.py
â”‚   â””â”€â”€ config.py               # Configuration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/              # Processed data files
â”œâ”€â”€ episodes/
â”‚   â””â”€â”€ episodes_all/           # 74,829 Episode JSONs
â”œâ”€â”€ results/                    # Training results
â”‚   â”œâ”€â”€ tabular_baselines/
â”‚   â”œâ”€â”€ text_only_baselines/
â”‚   â”œâ”€â”€ enhanced_gru/
â”‚   â”œâ”€â”€ fusion_baselines/
â”‚   â”œâ”€â”€ aligner_comparison/
â”‚   â”œâ”€â”€ calibration/
â”‚   â””â”€â”€ note_ablation/
â””â”€â”€ docs/                       # Documentation
    â”œâ”€â”€ DATA_CARD.md
    â”œâ”€â”€ ALIGNMENT_PROTOCOL_CARD.md
    â””â”€â”€ MODEL_CARD.md
```

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install pandas numpy scikit-learn xgboost torch tqdm
```

### Run Baselines

```bash
cd code/baselines

# Train tabular baselines (XGBoost, LR)
python train_tabular_baselines.py

# Train text-only model
python train_text_only.py

# Train enhanced GRU
python train_enhanced_gru.py

# Train fusion models
python train_fusion.py

# Run aligner comparison (Â±6h/Â±12h/Â±24h)
python train_aligner_comparison.py
```

### Evaluate

```bash
# Calibration metrics (ECE, Hosmer-Lemeshow)
python eval_calibration.py

# Note category ablation
python eval_note_ablation.py
```

---

## ğŸ“ˆ Benchmark Tasks

| Task | Definition | Positive Rate |
|------|------------|---------------|
| **In-Hospital Mortality** | Death during hospital stay | ~12.4% |
| **Prolonged LOS** | ICU stay > 7 days | ~15.2% |

---

## ğŸ”¬ Alignment Windows

| Window | AUROC | Recommendation |
|--------|-------|----------------|
| Â±6h | 0.777 | High precision, low coverage |
| Â±12h | 0.800 | Balanced |
| **Â±24h** | **0.833** | Best performance |

---

## ğŸ“„ Documentation

- [Data Card](docs/DATA_CARD.md) - Dataset description and statistics
- [Alignment Protocol Card](docs/ALIGNMENT_PROTOCOL_CARD.md) - Time alignment details
- [Model Card](docs/MODEL_CARD.md) - Baseline model specifications

---

## ğŸ“Š Results Files

| File | Description |
|------|-------------|
| `results/tabular_baselines/tabular_results.csv` | XGBoost/LR results |
| `results/text_only_baselines/text_only_results.csv` | Text-only results |
| `results/enhanced_gru/enhanced_gru_results.csv` | Enhanced GRU results |
| `results/fusion_baselines/fusion_results.csv` | Early/Late fusion results |
| `results/aligner_comparison/aligner_results.csv` | Window comparison |
| `results/calibration/calibration_results.csv` | ECE/HL metrics |
| `results/note_ablation/note_ablation_results.csv` | Note category ablation |

---

## ğŸ“œ Citation

```bibtex
@misc{timely-bench-2025,
  title={TIMELY-Bench: A Benchmark for Time-Aligned Fusion of 
         Clinical Time-Series and Notes in MIMIC},
  author={[Author Name]},
  year={2025},
  institution={King's College London}
}
```

---

## ğŸ“ License

This project uses MIMIC-IV data, which requires PhysioNet Credentialed Access.

---

## ğŸ™ Acknowledgments

- MIMIC-IV Database (PhysioNet)
- King's College London, Department of Informatics
